{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tico/anaconda3/envs/ds_project_env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2859 - loss: 1.3859 - val_accuracy: 0.4020 - val_loss: 1.3760\n",
      "Epoch 2/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2911 - loss: 1.3834 - val_accuracy: 0.3922 - val_loss: 1.3622\n",
      "Epoch 3/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2837 - loss: 1.3824 - val_accuracy: 0.4118 - val_loss: 1.3437\n",
      "Epoch 4/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3070 - loss: 1.3636 - val_accuracy: 0.3922 - val_loss: 1.3509\n",
      "Epoch 5/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3261 - loss: 1.3727 - val_accuracy: 0.4118 - val_loss: 1.3400\n",
      "Epoch 6/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3116 - loss: 1.3611 - val_accuracy: 0.3922 - val_loss: 1.3416\n",
      "Epoch 7/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2854 - loss: 1.3781 - val_accuracy: 0.4118 - val_loss: 1.3289\n",
      "Epoch 8/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3692 - loss: 1.3470 - val_accuracy: 0.3922 - val_loss: 1.3422\n",
      "Epoch 9/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3086 - loss: 1.3568 - val_accuracy: 0.4020 - val_loss: 1.3318\n",
      "Epoch 10/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3161 - loss: 1.3608 - val_accuracy: 0.4020 - val_loss: 1.3311\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "RandomForest Classifier:\n",
      "Train Accuracy: 0.8863, Train F1 Score: 0.8896\n",
      "Test Accuracy: 0.3125, Test F1 Score: 0.3014\n",
      "\n",
      "XGBoost Classifier:\n",
      "Train Accuracy: 0.8824, Train F1 Score: 0.8858\n",
      "Test Accuracy: 0.3125, Test F1 Score: 0.3049\n",
      "\n",
      "K-Nearest Neighbors Classifier:\n",
      "Train Accuracy: 0.4608, Train F1 Score: 0.4502\n",
      "Test Accuracy: 0.2500, Test F1 Score: 0.2370\n",
      "\n",
      "Convolutional Neural Network:\n",
      "Train Accuracy: 0.3373, Train F1 Score: 0.1912\n",
      "Test Accuracy: 0.3125, Test F1 Score: 0.1584\n"
     ]
    }
   ],
   "source": [
    "# Paths to data\n",
    "data_pkls_path = '/home/tico/Desktop/master_classes/project/orbits_4-5_4'\n",
    "behavior_path = '/home/tico/Desktop/master_classes/project/behavior/'\n",
    "\n",
    "# Load file names\n",
    "file_names = os.listdir(data_pkls_path)\n",
    "behavior_files = os.listdir(behavior_path)\n",
    "\n",
    "# Load behavior data\n",
    "behavior_source = pd.read_csv(os.path.join(behavior_path, behavior_files[0]), sep='\\t')\n",
    "for behavior_file in behavior_files[1:]:\n",
    "    curr_behavior_source = pd.read_csv(os.path.join(behavior_path, behavior_file), sep='\\t')\n",
    "    behavior_source = pd.concat([behavior_source, curr_behavior_source], axis=0)\n",
    "behavior_source = behavior_source[[\"session_id\", \"Group\"]]\n",
    "\n",
    "# Load pickle files and ensure consistent shape\n",
    "data_list = []\n",
    "data_list_cnn = []\n",
    "labels = []\n",
    "for file_name in file_names:\n",
    "    session_id = file_name.split('.')[0]\n",
    "    with open(os.path.join(data_pkls_path, file_name), 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "    data_list_cnn.append(data)\n",
    "    data_sum = data.sum(axis=0)\n",
    "    data_list.append(data_sum)\n",
    "    label = behavior_source.loc[behavior_source['session_id'] == session_id, 'Group'].values[0]\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(data_list)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Normalize the CNN data\n",
    "data_list_cnn = np.array(data_list_cnn, dtype='float32')\n",
    "data_list_cnn /= data_list_cnn.max()  # Normalize to the range [0, 1]\n",
    "\n",
    "# Split data into training and testing sets for RandomForest, XGBoost, and KNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation for RandomForest\n",
    "y_train_pred_rf = rf_clf.predict(X_train)\n",
    "y_test_pred_rf = rf_clf.predict(X_test)\n",
    "rf_train_accuracy = accuracy_score(y_train, y_train_pred_rf)\n",
    "rf_test_accuracy = accuracy_score(y_test, y_test_pred_rf)\n",
    "rf_train_f1 = f1_score(y_train, y_train_pred_rf, average='weighted')\n",
    "rf_test_f1 = f1_score(y_test, y_test_pred_rf, average='weighted')\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation for XGBoost\n",
    "y_train_pred_xgb = xgb_clf.predict(X_train)\n",
    "y_test_pred_xgb = xgb_clf.predict(X_test)\n",
    "xgb_train_accuracy = accuracy_score(y_train, y_train_pred_xgb)\n",
    "xgb_test_accuracy = accuracy_score(y_test, y_test_pred_xgb)\n",
    "xgb_train_f1 = f1_score(y_train, y_train_pred_xgb, average='weighted')\n",
    "xgb_test_f1 = f1_score(y_test, y_test_pred_xgb, average='weighted')\n",
    "\n",
    "# Train K-Nearest Neighbors classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation for KNN\n",
    "y_train_pred_knn = knn_clf.predict(X_train)\n",
    "y_test_pred_knn = knn_clf.predict(X_test)\n",
    "knn_train_accuracy = accuracy_score(y_train, y_train_pred_knn)\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred_knn)\n",
    "knn_train_f1 = f1_score(y_train, y_train_pred_knn, average='weighted')\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred_knn, average='weighted')\n",
    "\n",
    "# Split data into training and testing sets for CNN\n",
    "data_list_cnn = data_list_cnn[..., np.newaxis]  # Add a channel dimension\n",
    "X_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = train_test_split(data_list_cnn, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build CNN model\n",
    "input_shape = X_train_CNN.shape[1:]  # Update input_shape to include the channel dimension\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_CNN, y_train_CNN, epochs=10, batch_size=6, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_train_loss, cnn_train_accuracy = model.evaluate(X_train_CNN, y_train_CNN, verbose=0)\n",
    "cnn_test_loss, cnn_test_accuracy = model.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "\n",
    "# Predictions and evaluation for CNN\n",
    "y_train_pred_cnn = model.predict(X_train_CNN)\n",
    "y_test_pred_cnn = model.predict(X_test_CNN)\n",
    "cnn_train_f1 = f1_score(np.argmax(y_train_CNN, axis=1), np.argmax(y_train_pred_cnn, axis=1), average='weighted')\n",
    "cnn_test_f1 = f1_score(np.argmax(y_test_CNN, axis=1), np.argmax(y_test_pred_cnn, axis=1), average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(\"RandomForest Classifier:\")\n",
    "print(f\"Train Accuracy: {rf_train_accuracy:.4f}, Train F1 Score: {rf_train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {rf_test_accuracy:.4f}, Test F1 Score: {rf_test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nXGBoost Classifier:\")\n",
    "print(f\"Train Accuracy: {xgb_train_accuracy:.4f}, Train F1 Score: {xgb_train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {xgb_test_accuracy:.4f}, Test F1 Score: {xgb_test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classifier:\")\n",
    "print(f\"Train Accuracy: {knn_train_accuracy:.4f}, Train F1 Score: {knn_train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {knn_test_accuracy:.4f}, Test F1 Score: {knn_test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConvolutional Neural Network:\")\n",
    "print(f\"Train Accuracy: {cnn_train_accuracy:.4f}, Train F1 Score: {cnn_train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {cnn_test_accuracy:.4f}, Test F1 Score: {cnn_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_agreement_arith(orbits1, orbits2):\n",
    "    # Ensure the orbit counts are in numpy arrays for easier manipulation\n",
    "    orbits1 = np.array(orbits1, dtype=float)\n",
    "    orbits2 = np.array(orbits2, dtype=float)\n",
    "\n",
    "    # Avoid log of zero by replacing zero values with a small number\n",
    "    orbits1[orbits1 == 0] = 1e-10\n",
    "    orbits2[orbits2 == 0] = 1e-10\n",
    "\n",
    "    # Calculate the logarithm of orbit frequencies\n",
    "    log_orbits1 = np.log(orbits1)\n",
    "    log_orbits2 = np.log(orbits2)\n",
    "\n",
    "    # Calculate orbit agreement Ai for each orbit type\n",
    "    Ai = 1 - np.sqrt(0.5 * np.sum((log_orbits1 - log_orbits2)**2, axis=1))\n",
    "    # Make sure Ai does not contain invalid values for the geometric mean\n",
    "    Ai[Ai <= 0] = 1e-10  # Replace non-positive values with a small positive number\n",
    "    # Arithmetic and geometric means of Ai\n",
    "    A_arithmetic = np.mean(Ai)\n",
    "\n",
    "    return 1-A_arithmetic\n",
    "def calculate_agreement_geom(orbits1, orbits2):\n",
    "    # Ensure the orbit counts are in numpy arrays for easier manipulation\n",
    "    orbits1 = np.array(orbits1, dtype=float)\n",
    "    orbits2 = np.array(orbits2, dtype=float)\n",
    "\n",
    "    # Avoid log of zero by replacing zero values with a small number\n",
    "    orbits1[orbits1 == 0] = 1e-10\n",
    "    orbits2[orbits2 == 0] = 1e-10\n",
    "\n",
    "    # Calculate the logarithm of orbit frequencies\n",
    "    log_orbits1 = np.log(orbits1)\n",
    "    log_orbits2 = np.log(orbits2)\n",
    "\n",
    "    # Calculate orbit agreement Ai for each orbit type\n",
    "    Ai = 1 - np.sqrt(0.5 * np.sum((log_orbits1 - log_orbits2)**2, axis=1))\n",
    "    # Make sure Ai does not contain invalid values for the geometric mean\n",
    "    Ai[Ai <= 0] = 1e-10  # Replace non-positive values with a small positive number\n",
    "    # Arithmetic and geometric means of Ai\n",
    "    A_geometric = np.prod(np.power(Ai, 1/len(Ai)))\n",
    "\n",
    "    return 1-A_geometric\n",
    "def custom_distance_wrapper(metric_func):\n",
    "    def wrapped_metric(x, y):\n",
    "        # Reshape the flattened arrays back to their original 2D shape\n",
    "        original_shape = (x.size // 2, 2)\n",
    "        x_reshaped = x.reshape(original_shape)\n",
    "        y_reshaped = y.reshape(original_shape)\n",
    "        # Apply the custom distance function\n",
    "        return metric_func(x_reshaped, y_reshaped)\n",
    "    return wrapped_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors Classifier (Arithmetic):\n",
      "Train Accuracy: 0.5098, Train F1 Score: 0.4932\n",
      "Test Accuracy: 0.2656, Test F1 Score: 0.2558\n",
      "\n",
      "K-Nearest Neighbors Classifier (Geometric):\n",
      "Train Accuracy: 0.4824, Train F1 Score: 0.4641\n",
      "Test Accuracy: 0.3281, Test F1 Score: 0.3180\n"
     ]
    }
   ],
   "source": [
    "# Paths to data\n",
    "data_pkls_path = '/home/tico/Desktop/master_classes/project/orbits_4-2_4'\n",
    "behavior_path = '/home/tico/Desktop/master_classes/project/behavior/'\n",
    "\n",
    "# Load file names\n",
    "file_names = os.listdir(data_pkls_path)\n",
    "behavior_files = os.listdir(behavior_path)\n",
    "\n",
    "# Load behavior data\n",
    "behavior_source = pd.read_csv(os.path.join(behavior_path, behavior_files[0]), sep='\\t')\n",
    "for behavior_file in behavior_files[1:]:\n",
    "    curr_behavior_source = pd.read_csv(os.path.join(behavior_path, behavior_file), sep='\\t')\n",
    "    behavior_source = pd.concat([behavior_source, curr_behavior_source], axis=0)\n",
    "behavior_source = behavior_source[[\"session_id\", \"Group\"]]\n",
    "\n",
    "# Load pickle files and ensure consistent shape\n",
    "data_list = []\n",
    "labels = []\n",
    "for file_name in file_names:\n",
    "    session_id = file_name.split('.')[0]\n",
    "    with open(os.path.join(data_pkls_path, file_name), 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "    data_list.append(data)\n",
    "    label = behavior_source.loc[behavior_source['session_id'] == session_id, 'Group'].values[0]\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(data_list)\n",
    "y = np.array(labels)\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Flatten the 2D data instances into 1D arrays\n",
    "X_flattened = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create wrapped distance functions for KNeighborsClassifier\n",
    "wrapped_calculate_agreement_arith = custom_distance_wrapper(calculate_agreement_arith)\n",
    "wrapped_calculate_agreement_geom = custom_distance_wrapper(calculate_agreement_geom)\n",
    "\n",
    "# Train K-Nearest Neighbors classifier with arithmetic agreement\n",
    "knn_clf_arith = KNeighborsClassifier(n_neighbors=6, metric=wrapped_calculate_agreement_arith)\n",
    "knn_clf_arith.fit(X_train, y_train)\n",
    "\n",
    "# Train K-Nearest Neighbors classifier with geometric agreement\n",
    "knn_clf_geom = KNeighborsClassifier(n_neighbors=6, metric=wrapped_calculate_agreement_geom)\n",
    "knn_clf_geom.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation for KNN with arithmetic agreement\n",
    "y_train_pred_knn_arith = knn_clf_arith.predict(X_train)\n",
    "y_test_pred_knn_arith = knn_clf_arith.predict(X_test)\n",
    "knn_train_accuracy_arith = accuracy_score(y_train, y_train_pred_knn_arith)\n",
    "knn_test_accuracy_arith = accuracy_score(y_test, y_test_pred_knn_arith)\n",
    "knn_train_f1_arith = f1_score(y_train, y_train_pred_knn_arith, average='weighted')\n",
    "knn_test_f1_arith = f1_score(y_test, y_test_pred_knn_arith, average='weighted')\n",
    "print(\"\\nK-Nearest Neighbors Classifier (Arithmetic):\")\n",
    "print(f\"Train Accuracy: {knn_train_accuracy_arith:.4f}, Train F1 Score: {knn_train_f1_arith:.4f}\")\n",
    "print(f\"Test Accuracy: {knn_test_accuracy_arith:.4f}, Test F1 Score: {knn_test_f1_arith:.4f}\")\n",
    "\n",
    "# Predictions and evaluation for KNN with geometric agreement\n",
    "y_train_pred_knn_geom = knn_clf_geom.predict(X_train)\n",
    "y_test_pred_knn_geom = knn_clf_geom.predict(X_test)\n",
    "knn_train_accuracy_geom = accuracy_score(y_train, y_train_pred_knn_geom)\n",
    "knn_test_accuracy_geom = accuracy_score(y_test, y_test_pred_knn_geom)\n",
    "knn_train_f1_geom = f1_score(y_train, y_train_pred_knn_geom, average='weighted')\n",
    "knn_test_f1_geom = f1_score(y_test, y_test_pred_knn_geom, average='weighted')\n",
    "print(\"\\nK-Nearest Neighbors Classifier (Geometric):\")\n",
    "print(f\"Train Accuracy: {knn_train_accuracy_geom:.4f}, Train F1 Score: {knn_train_f1_geom:.4f}\")\n",
    "print(f\"Test Accuracy: {knn_test_accuracy_geom:.4f}, Test F1 Score: {knn_test_f1_geom:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
