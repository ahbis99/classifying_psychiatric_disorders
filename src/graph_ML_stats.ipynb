{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors:\n",
      "  Dataset 1 Accuracy: 0.2500\n",
      "  Dataset 2 Accuracy: 0.2266\n",
      "\n",
      "Random Forest:\n",
      "  Dataset 1 Accuracy: 0.3438\n",
      "  Dataset 2 Accuracy: 0.1953\n",
      "\n",
      "XGBoost:\n",
      "  Dataset 1 Accuracy: 0.3359\n",
      "  Dataset 2 Accuracy: 0.2188\n",
      "\n",
      "Logistic Regression:\n",
      "  Dataset 1 Accuracy: 0.2734\n",
      "  Dataset 2 Accuracy: 0.2734\n",
      "\n",
      "MLP Classifier:\n",
      "  Dataset 1 Accuracy: 0.2969\n",
      "  Dataset 2 Accuracy: 0.2656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tico/anaconda3/envs/ds_project_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/tico/anaconda3/envs/ds_project_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#these graphs will have the following columns:\n",
    "#File Name,label,Number of Nodes,Number of Edges,Average Degree,Theoretical Avg Clustering,Average Clustering,Theoretical Avg Path Length,Average Path Length,Log of Nodes,Log Log of Nodes,Size of Largest CC\n",
    "#You can avoid to use the following columns: File Name\n",
    "#the label of each row can be found in the column: label\n",
    "#Can you run several machine learning algorithms over these datasets. Partition each dataset into training and testing sets and then report accuracy\n",
    "# in each dataset seperatly. Use classification methods fron K neirest neighbors, Random Forests, XGBoost, regularization methods, MLPs\n",
    "# Load the datasets\n",
    "# Load the datasets\n",
    "csv_path1 = 'graph_statistics-4.5.csv'\n",
    "csv_path2 = 'graph_statistics.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv_path1)\n",
    "df2 = pd.read_csv(csv_path2)\n",
    "\n",
    "# Drop 'File Name' column and separate features and labels\n",
    "def prepare_data(df):\n",
    "    df = df.drop(columns=['File Name'])\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label']\n",
    "    return X, y\n",
    "\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y1 = label_encoder.fit_transform(y1)\n",
    "y2 = label_encoder.fit_transform(y2)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.fit_transform(X2)\n",
    "\n",
    "# Split datasets into training and testing sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate the classifiers on both datasets\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X1_train, y1_train)\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "    acc1 = accuracy_score(y1_test, y1_pred)\n",
    "    \n",
    "    clf.fit(X2_train, y2_train)\n",
    "    y2_pred = clf.predict(X2_test)\n",
    "    acc2 = accuracy_score(y2_test, y2_pred)\n",
    "    \n",
    "    results[name] = {'Dataset 1 Accuracy': acc1, 'Dataset 2 Accuracy': acc2}\n",
    "\n",
    "# Display the results\n",
    "for clf_name, acc in results.items():\n",
    "    print(f\"{clf_name}:\")\n",
    "    print(f\"  Dataset 1 Accuracy: {acc['Dataset 1 Accuracy']:.4f}\")\n",
    "    print(f\"  Dataset 2 Accuracy: {acc['Dataset 2 Accuracy']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary DataFrame 1 STD: 4.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Number of Nodes</th>\n",
       "      <th>Number of Edges</th>\n",
       "      <th>Average Degree</th>\n",
       "      <th>Theoretical Avg Clustering</th>\n",
       "      <th>Average Clustering</th>\n",
       "      <th>Theoretical Avg Path Length</th>\n",
       "      <th>Average Path Length</th>\n",
       "      <th>Log of Nodes</th>\n",
       "      <th>Log Log of Nodes</th>\n",
       "      <th>Size of Largest CC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>5083.513333</td>\n",
       "      <td>14.160204</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.109788</td>\n",
       "      <td>12.080619</td>\n",
       "      <td>4.309249</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>146.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON</td>\n",
       "      <td>718.0</td>\n",
       "      <td>1672.450495</td>\n",
       "      <td>4.658636</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>9.371822</td>\n",
       "      <td>4.003032</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>118.435644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SADP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>2622.663866</td>\n",
       "      <td>7.305470</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.094796</td>\n",
       "      <td>8.181540</td>\n",
       "      <td>4.107825</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>147.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCZP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>8815.347305</td>\n",
       "      <td>24.555285</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.120812</td>\n",
       "      <td>6.689573</td>\n",
       "      <td>4.355858</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>156.892216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  Number of Nodes  Number of Edges  Average Degree  \\\n",
       "0   BPP            718.0      5083.513333       14.160204   \n",
       "1   CON            718.0      1672.450495        4.658636   \n",
       "2  SADP            718.0      2622.663866        7.305470   \n",
       "3  SCZP            718.0      8815.347305       24.555285   \n",
       "\n",
       "   Theoretical Avg Clustering  Average Clustering  \\\n",
       "0                    0.019749            0.109788   \n",
       "1                    0.006497            0.089422   \n",
       "2                    0.010189            0.094796   \n",
       "3                    0.034247            0.120812   \n",
       "\n",
       "   Theoretical Avg Path Length  Average Path Length  Log of Nodes  \\\n",
       "0                    12.080619             4.309249       6.57647   \n",
       "1                     9.371822             4.003032       6.57647   \n",
       "2                     8.181540             4.107825       6.57647   \n",
       "3                     6.689573             4.355858       6.57647   \n",
       "\n",
       "   Log Log of Nodes  Size of Largest CC  \n",
       "0          1.883498          146.413333  \n",
       "1          1.883498          118.435644  \n",
       "2          1.883498          147.941176  \n",
       "3          1.883498          156.892216  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "csv_path1 = 'graph_statistics-4.5.csv'\n",
    "csv_path2 = 'graph_statistics.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv_path1)\n",
    "df2 = pd.read_csv(csv_path2)\n",
    "\n",
    "# Drop 'File Name' column\n",
    "df1 = df1.drop(columns=['File Name'])\n",
    "df2 = df2.drop(columns=['File Name'])\n",
    "\n",
    "# Group by 'label' and calculate the mean for each group\n",
    "summary_df1 = df1.groupby('label').mean().reset_index()\n",
    "summary_df2 = df2.groupby('label').mean().reset_index()\n",
    "\n",
    "# Display the summary dataframes4\n",
    "print(\"Summary DataFrame 1 STD: .5\")\n",
    "summary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary DataFrame 2 STD: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Number of Nodes</th>\n",
       "      <th>Number of Edges</th>\n",
       "      <th>Average Degree</th>\n",
       "      <th>Theoretical Avg Clustering</th>\n",
       "      <th>Average Clustering</th>\n",
       "      <th>Theoretical Avg Path Length</th>\n",
       "      <th>Average Path Length</th>\n",
       "      <th>Log of Nodes</th>\n",
       "      <th>Log Log of Nodes</th>\n",
       "      <th>Size of Largest CC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>82137.066667</td>\n",
       "      <td>228.794058</td>\n",
       "      <td>0.319099</td>\n",
       "      <td>0.553685</td>\n",
       "      <td>1.228181</td>\n",
       "      <td>1.689993</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>717.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON</td>\n",
       "      <td>718.0</td>\n",
       "      <td>78250.405941</td>\n",
       "      <td>217.967705</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.550745</td>\n",
       "      <td>1.230697</td>\n",
       "      <td>1.705816</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>717.876238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SADP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>78832.075630</td>\n",
       "      <td>219.587954</td>\n",
       "      <td>0.306259</td>\n",
       "      <td>0.541535</td>\n",
       "      <td>1.231511</td>\n",
       "      <td>1.704423</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>717.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCZP</td>\n",
       "      <td>718.0</td>\n",
       "      <td>84185.670659</td>\n",
       "      <td>234.500475</td>\n",
       "      <td>0.327058</td>\n",
       "      <td>0.557667</td>\n",
       "      <td>1.224293</td>\n",
       "      <td>1.681004</td>\n",
       "      <td>6.57647</td>\n",
       "      <td>1.883498</td>\n",
       "      <td>717.886228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  Number of Nodes  Number of Edges  Average Degree  \\\n",
       "0   BPP            718.0     82137.066667      228.794058   \n",
       "1   CON            718.0     78250.405941      217.967705   \n",
       "2  SADP            718.0     78832.075630      219.587954   \n",
       "3  SCZP            718.0     84185.670659      234.500475   \n",
       "\n",
       "   Theoretical Avg Clustering  Average Clustering  \\\n",
       "0                    0.319099            0.553685   \n",
       "1                    0.304000            0.550745   \n",
       "2                    0.306259            0.541535   \n",
       "3                    0.327058            0.557667   \n",
       "\n",
       "   Theoretical Avg Path Length  Average Path Length  Log of Nodes  \\\n",
       "0                     1.228181             1.689993       6.57647   \n",
       "1                     1.230697             1.705816       6.57647   \n",
       "2                     1.231511             1.704423       6.57647   \n",
       "3                     1.224293             1.681004       6.57647   \n",
       "\n",
       "   Log Log of Nodes  Size of Largest CC  \n",
       "0          1.883498          717.833333  \n",
       "1          1.883498          717.876238  \n",
       "2          1.883498          717.840336  \n",
       "3          1.883498          717.886228  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSummary DataFrame 2 STD: 2\")\n",
    "summary_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
