{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_target\n",
      "0    436\n",
      "1    202\n",
      "Name: count, dtype: int64\n",
      "Group\n",
      "CON     202\n",
      "SCZP    167\n",
      "BPP     150\n",
      "SADP    119\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_target</th>\n",
       "      <th>Group</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X709</th>\n",
       "      <th>X710</th>\n",
       "      <th>X711</th>\n",
       "      <th>X712</th>\n",
       "      <th>X713</th>\n",
       "      <th>X714</th>\n",
       "      <th>X715</th>\n",
       "      <th>X716</th>\n",
       "      <th>X717</th>\n",
       "      <th>X718</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SADP</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>-0.013089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.007422</td>\n",
       "      <td>-0.003942</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SCZP</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>-0.005585</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>-0.007209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>-0.007612</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.005739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>BPP</td>\n",
       "      <td>-0.011590</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>-0.018124</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.003363</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.007613</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>-0.003668</td>\n",
       "      <td>0.005865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>SCZP</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>-0.004097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006566</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.006735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>SADP</td>\n",
       "      <td>-0.025011</td>\n",
       "      <td>0.031992</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.009084</td>\n",
       "      <td>-0.002958</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004469</td>\n",
       "      <td>0.037608</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.017834</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>0.039692</td>\n",
       "      <td>0.029756</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   binary_target Group        X1        X2        X3        X4        X5  \\\n",
       "0              0  SADP  0.017901  0.009985  0.003740  0.012205  0.005254   \n",
       "1              0  SCZP  0.006281  0.014014 -0.005585 -0.000536  0.003254   \n",
       "2              0   BPP -0.011590  0.009900 -0.008592 -0.009722  0.001935   \n",
       "3              0  SCZP  0.017341  0.009125  0.001433  0.005714  0.000891   \n",
       "4              0  SADP -0.025011  0.031992 -0.037631 -0.024702 -0.009084   \n",
       "\n",
       "         X6        X7        X8  ...      X709      X710      X711      X712  \\\n",
       "0  0.023362  0.009241 -0.013089  ...  0.014800 -0.000650 -0.007422 -0.003942   \n",
       "1  0.008885  0.008263 -0.007209  ... -0.002154  0.007586  0.004824  0.008781   \n",
       "2  0.016690  0.007919 -0.006034  ... -0.003193 -0.018124  0.012447 -0.000854   \n",
       "3  0.004737  0.000913 -0.004097  ... -0.006566  0.018083  0.007969  0.005143   \n",
       "4 -0.002958  0.031740  0.018152  ... -0.004469  0.037608  0.032018  0.005771   \n",
       "\n",
       "       X713      X714      X715      X716      X717      X718  \n",
       "0  0.005397  0.000533  0.013678 -0.014425  0.000760  0.000889  \n",
       "1 -0.007612  0.005459  0.004697  0.002705  0.008613  0.005739  \n",
       "2 -0.003363  0.001340 -0.007613  0.001474 -0.003668  0.005865  \n",
       "3  0.010550  0.000927  0.015112  0.003535  0.008583  0.006735  \n",
       "4  0.000471  0.017834  0.020844  0.039692  0.029756  0.003653  \n",
       "\n",
       "[5 rows x 720 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'path_to_csv' with the actual path to your CSV file\n",
    "data = pd.read_csv(r'C:\\Users\\manfr\\OneDrive\\Escritorio\\Manfred\\EMAI\\SecondSemester_Slovenia\\Project\\BSNIP_data\\BSNIP_data\\neural\\neural_parcellated_gbc.csv')\n",
    "\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data['binary_target'] = (data['Group'] == 'CON').astype(int)\n",
    "unique_value_counts_binary = data['binary_target'].value_counts()\n",
    "unique_value_counts_multiclass = data['Group'].value_counts()\n",
    "print(unique_value_counts_binary)\n",
    "print(unique_value_counts_multiclass)\n",
    "# Create a list of the new column order\n",
    "columns = ['binary_target', 'Group'] + [col for col in data.columns if col not in ['binary_target', 'Group']]\n",
    "\n",
    "# Reindex the DataFrame with the new column order\n",
    "data = data[columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 718) (128, 718) (510,) (128,)\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "binary_data = data.drop('Group', axis=1)\n",
    "input_features = binary_data.drop('binary_target', axis=1).values\n",
    "targets = binary_data['binary_target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_features, targets, test_size=0.2, random_state=seed)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=seed)\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 1.0\n",
      "XGBoost Test Accuracy: 0.984375\n",
      "XGBoost Training Misclassification Rate: 0.0\n",
      "XGBoost Test Misclassification Rate: 0.015625\n",
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Test Accuracy: 0.9765625\n",
      "Random Forest Training Misclassification Rate: 0.0\n",
      "Random Forest Test Misclassification Rate: 0.0234375\n",
      "XGBoost Training Misclassification SE: 0.0\n",
      "XGBoost Test Misclassification SE: 0.010961886875314282\n",
      "Random Forest Training Misclassification SE: 0.0\n",
      "Random Forest Test Misclassification SE: 0.01337213275159097\n"
     ]
    }
   ],
   "source": [
    "# For XGBoost Model\n",
    "# Make predictions on training and test sets\n",
    "xgb_train_predictions = xgb_clf.predict(X_train)\n",
    "xgb_test_predictions = xgb_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "xgb_train_accuracy = accuracy_score(y_train, xgb_train_predictions)\n",
    "xgb_test_accuracy = accuracy_score(y_test, xgb_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "xgb_train_misclassification = 1 - xgb_train_accuracy\n",
    "xgb_test_misclassification = 1 - xgb_test_accuracy\n",
    "\n",
    "# For Random Forest Model\n",
    "# Make predictions on training and test sets\n",
    "rf_train_predictions = rf_clf.predict(X_train)\n",
    "rf_test_predictions = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_predictions)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "rf_train_misclassification = 1 - rf_train_accuracy\n",
    "rf_test_misclassification = 1 - rf_test_accuracy\n",
    "\n",
    "# Print results\n",
    "print(\"XGBoost Training Accuracy:\", xgb_train_accuracy)\n",
    "print(\"XGBoost Test Accuracy:\", xgb_test_accuracy)\n",
    "print(\"XGBoost Training Misclassification Rate:\", xgb_train_misclassification)\n",
    "print(\"XGBoost Test Misclassification Rate:\", xgb_test_misclassification)\n",
    "\n",
    "print(\"Random Forest Training Accuracy:\", rf_train_accuracy)\n",
    "print(\"Random Forest Test Accuracy:\", rf_test_accuracy)\n",
    "print(\"Random Forest Training Misclassification Rate:\", rf_train_misclassification)\n",
    "print(\"Random Forest Test Misclassification Rate:\", rf_test_misclassification)\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for XGBoost\n",
    "xgb_train_se = np.sqrt((xgb_train_misclassification * (1 - xgb_train_misclassification)) / len(X_train))\n",
    "xgb_test_se = np.sqrt((xgb_test_misclassification * (1 - xgb_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for Random Forest\n",
    "rf_train_se = np.sqrt((rf_train_misclassification * (1 - rf_train_misclassification)) / len(X_train))\n",
    "rf_test_se = np.sqrt((rf_test_misclassification * (1 - rf_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Print the standard errors\n",
    "print(\"XGBoost Training Misclassification SE:\", xgb_train_se)\n",
    "print(\"XGBoost Test Misclassification SE:\", xgb_test_se)\n",
    "print(\"Random Forest Training Misclassification SE:\", rf_train_se)\n",
    "print(\"Random Forest Test Misclassification SE:\", rf_test_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 718) (128, 718) (510,) (128,)\n",
      "Target Values statistics of: y_train\n",
      "Value: BPP, Count: 120\n",
      "Value: CON, Count: 161\n",
      "Value: SADP, Count: 95\n",
      "Value: SCZP, Count: 134\n",
      "Target Values statistics of: y_test\n",
      "Value: BPP, Count: 30\n",
      "Value: CON, Count: 41\n",
      "Value: SADP, Count: 24\n",
      "Value: SCZP, Count: 33\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "binary_data = data.drop('binary_target', axis=1)\n",
    "input_features = binary_data.drop('Group', axis=1).values\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "targets_numeric = le.fit_transform(binary_data['Group'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_features, targets_numeric, \n",
    "                                                    test_size=0.2, random_state=seed, \n",
    "                                                    stratify=targets_numeric)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Access the mapping of encoded labels back to original class names\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "for target_values, name in [(y_train,'y_train'),(y_test,'y_test')]:\n",
    "    # Get unique values and their counts\n",
    "    unique_values, counts = np.unique(target_values, return_counts=True)\n",
    "    print(f'Target Values statistics of: {name}')\n",
    "    # Display the unique values and their counts\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        print(f\"Value: {label_mapping[value]}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', n_estimators=100, seed=seed)\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 1.0\n",
      "XGBoost Test Accuracy: 0.578125\n",
      "XGBoost Training Misclassification Rate: 0.0\n",
      "XGBoost Test Misclassification Rate: 0.421875\n",
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Test Accuracy: 0.5859375\n",
      "Random Forest Training Misclassification Rate: 0.0\n",
      "Random Forest Test Misclassification Rate: 0.4140625\n",
      "XGBoost Training Misclassification SE: 0.0\n",
      "XGBoost Test Misclassification SE: 0.04365136062231838\n",
      "Random Forest Training Misclassification SE: 0.0\n",
      "Random Forest Test Misclassification SE: 0.043536510010075705\n"
     ]
    }
   ],
   "source": [
    "# For XGBoost Model\n",
    "# Make predictions on training and test sets\n",
    "xgb_train_predictions = xgb_clf.predict(X_train)\n",
    "xgb_test_predictions = xgb_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "xgb_train_accuracy = accuracy_score(y_train, xgb_train_predictions)\n",
    "xgb_test_accuracy = accuracy_score(y_test, xgb_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "xgb_train_misclassification = 1 - xgb_train_accuracy\n",
    "xgb_test_misclassification = 1 - xgb_test_accuracy\n",
    "\n",
    "# For Random Forest Model\n",
    "# Make predictions on training and test sets\n",
    "rf_train_predictions = rf_clf.predict(X_train)\n",
    "rf_test_predictions = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_predictions)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "rf_train_misclassification = 1 - rf_train_accuracy\n",
    "rf_test_misclassification = 1 - rf_test_accuracy\n",
    "\n",
    "# Print results\n",
    "print(\"XGBoost Training Accuracy:\", xgb_train_accuracy)\n",
    "print(\"XGBoost Test Accuracy:\", xgb_test_accuracy)\n",
    "print(\"XGBoost Training Misclassification Rate:\", xgb_train_misclassification)\n",
    "print(\"XGBoost Test Misclassification Rate:\", xgb_test_misclassification)\n",
    "\n",
    "print(\"Random Forest Training Accuracy:\", rf_train_accuracy)\n",
    "print(\"Random Forest Test Accuracy:\", rf_test_accuracy)\n",
    "print(\"Random Forest Training Misclassification Rate:\", rf_train_misclassification)\n",
    "print(\"Random Forest Test Misclassification Rate:\", rf_test_misclassification)\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for XGBoost\n",
    "xgb_train_se = np.sqrt((xgb_train_misclassification * (1 - xgb_train_misclassification)) / len(X_train))\n",
    "xgb_test_se = np.sqrt((xgb_test_misclassification * (1 - xgb_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for Random Forest\n",
    "rf_train_se = np.sqrt((rf_train_misclassification * (1 - rf_train_misclassification)) / len(X_train))\n",
    "rf_test_se = np.sqrt((rf_test_misclassification * (1 - rf_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Print the standard errors\n",
    "print(\"XGBoost Training Misclassification SE:\", xgb_train_se)\n",
    "print(\"XGBoost Test Misclassification SE:\", xgb_test_se)\n",
    "print(\"Random Forest Training Misclassification SE:\", rf_train_se)\n",
    "print(\"Random Forest Test Misclassification SE:\", rf_test_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\manfr\\.conda\\envs\\project_env\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\manfr\\.conda\\envs\\project_env\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\manfr\\.conda\\envs\\project_env\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\manfr\\.conda\\envs\\project_env\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\manfr\\.conda\\envs\\project_env\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Downloading imbalanced_learn-0.12.0-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 257.7/257.7 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 718\n",
      "Reduced number of features: 171\n",
      "Value: BPP, Count: 161\n",
      "Value: CON, Count: 161\n",
      "Value: SADP, Count: 161\n",
      "Value: SCZP, Count: 161\n",
      "After augmentation to reach 300 samples per class:\n",
      "Value: BPP, Count: 300\n",
      "Value: CON, Count: 300\n",
      "Value: SADP, Count: 300\n",
      "Value: SCZP, Count: 300\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train, y_train are your initial training data\n",
    "\n",
    "# Train a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Select features based on importance\n",
    "selector = SelectFromModel(rf, prefit=True, threshold='mean')  # Selects features with importance higher than the mean importance\n",
    "\n",
    "# Transform training and testing sets\n",
    "X_train_reduced = selector.transform(X_train)\n",
    "X_test_reduced = selector.transform(X_test)\n",
    "\n",
    "print(f\"Original number of features: {X_train.shape[1]}\")\n",
    "print(f\"Reduced number of features: {X_train_reduced.shape[1]}\")\n",
    "\n",
    "smote = SMOTE(random_state=10)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_reduced, y_train)\n",
    "\n",
    "# Check the distribution after SMOTE\n",
    "unique_smote, counts_smote = np.unique(y_train_smote, return_counts=True)\n",
    "for value, count in zip(unique_smote, counts_smote):\n",
    "    print(f\"Value: {label_mapping[value]}, Count: {count}\")\n",
    "\n",
    "# Determine the desired number of samples for each class\n",
    "desired_counts = 300\n",
    "target_counts = {label: desired_counts for label in np.unique(y_train_smote)}\n",
    "\n",
    "# Initialize RandomOverSampler with the target_counts as the sampling strategy\n",
    "ros = RandomOverSampler(random_state=10, sampling_strategy=target_counts)\n",
    "\n",
    "# Now, apply RandomOverSampler to adjust class distribution to have 300 samples per class\n",
    "X_train_augmented, y_train_augmented = ros.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "# Verify the final distribution\n",
    "unique_augmented, counts_augmented = np.unique(y_train_augmented, return_counts=True)\n",
    "print('After augmentation to reach 300 samples per class:')\n",
    "for value, count in zip(unique_augmented, counts_augmented):\n",
    "    print(f\"Value: {label_mapping[value]}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', n_estimators=100, seed=seed)\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 1.0\n",
      "XGBoost Test Accuracy: 0.6015625\n",
      "XGBoost Training Misclassification Rate: 0.0\n",
      "XGBoost Test Misclassification Rate: 0.3984375\n",
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Test Accuracy: 0.5859375\n",
      "Random Forest Training Misclassification Rate: 0.0\n",
      "Random Forest Test Misclassification Rate: 0.4140625\n",
      "XGBoost Training Misclassification SE: 0.0\n",
      "XGBoost Test Misclassification SE: 0.04327284968965728\n",
      "Random Forest Training Misclassification SE: 0.0\n",
      "Random Forest Test Misclassification SE: 0.043536510010075705\n"
     ]
    }
   ],
   "source": [
    "# For XGBoost Model\n",
    "# Make predictions on training and test sets\n",
    "xgb_train_predictions = xgb_clf.predict(X_train_augmented)\n",
    "xgb_test_predictions = xgb_clf.predict(X_test_reduced)\n",
    "\n",
    "# Calculate accuracy\n",
    "xgb_train_accuracy = accuracy_score(y_train_augmented, xgb_train_predictions)\n",
    "xgb_test_accuracy = accuracy_score(y_test, xgb_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "xgb_train_misclassification = 1 - xgb_train_accuracy\n",
    "xgb_test_misclassification = 1 - xgb_test_accuracy\n",
    "\n",
    "# For Random Forest Model\n",
    "# Make predictions on training and test sets\n",
    "rf_train_predictions = rf_clf.predict(X_train_augmented)\n",
    "rf_test_predictions = rf_clf.predict(X_test_reduced)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_train_accuracy = accuracy_score(y_train_augmented, rf_train_predictions)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_predictions)\n",
    "\n",
    "# Calculate misclassification rate\n",
    "rf_train_misclassification = 1 - rf_train_accuracy\n",
    "rf_test_misclassification = 1 - rf_test_accuracy\n",
    "\n",
    "# Print results\n",
    "print(\"XGBoost Training Accuracy:\", xgb_train_accuracy)\n",
    "print(\"XGBoost Test Accuracy:\", xgb_test_accuracy)\n",
    "print(\"XGBoost Training Misclassification Rate:\", xgb_train_misclassification)\n",
    "print(\"XGBoost Test Misclassification Rate:\", xgb_test_misclassification)\n",
    "\n",
    "print(\"Random Forest Training Accuracy:\", rf_train_accuracy)\n",
    "print(\"Random Forest Test Accuracy:\", rf_test_accuracy)\n",
    "print(\"Random Forest Training Misclassification Rate:\", rf_train_misclassification)\n",
    "print(\"Random Forest Test Misclassification Rate:\", rf_test_misclassification)\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for XGBoost\n",
    "xgb_train_se = np.sqrt((xgb_train_misclassification * (1 - xgb_train_misclassification)) / len(X_train))\n",
    "xgb_test_se = np.sqrt((xgb_test_misclassification * (1 - xgb_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Calculate the standard error of the misclassification rate for Random Forest\n",
    "rf_train_se = np.sqrt((rf_train_misclassification * (1 - rf_train_misclassification)) / len(X_train))\n",
    "rf_test_se = np.sqrt((rf_test_misclassification * (1 - rf_test_misclassification)) / len(X_test))\n",
    "\n",
    "# Print the standard errors\n",
    "print(\"XGBoost Training Misclassification SE:\", xgb_train_se)\n",
    "print(\"XGBoost Test Misclassification SE:\", xgb_test_se)\n",
    "print(\"Random Forest Training Misclassification SE:\", rf_train_se)\n",
    "print(\"Random Forest Test Misclassification SE:\", rf_test_se)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
