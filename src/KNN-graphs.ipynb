{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph convolutional network for fMRI analysis based on connectivity neighborhood:\n",
    "The paper outlines a methodology for converting functional connectivity (FC) matrices from fMRI data into graph structures using a k-nearest neighbors (k-NN) approach. The k-NN graph is built by connecting each node (ROI) to its k nearest neighbors based on the strength of connectivity, which is represented by the FC matrix values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # Import tqdm for notebooks\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fc_matrix(file_path):\n",
    "    \"\"\" Load functional connectivity matrix from a .pconn.nii file. \"\"\"\n",
    "    img = nib.load(file_path)\n",
    "    fc_matrix = img.get_fdata()\n",
    "    return fc_matrix\n",
    "\n",
    "def create_knn_graph(fc_matrix, k=5):\n",
    "    \"\"\" Create a graph from a functional connectivity matrix using k-nearest neighbors based on absolute values. \"\"\"\n",
    "    n = fc_matrix.shape[0]  # Number of nodes\n",
    "    G = nx.Graph()\n",
    "    for i in range(n):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    # For each node, add edges to the k-nearest neighbors based on absolute values of connectivity strengths\n",
    "    for i in range(n):\n",
    "        # Sort indices based on the absolute values, get the k highest values indices for each row\n",
    "        indices = np.argsort(np.abs(fc_matrix[i]))[-k:]\n",
    "        for j in indices:\n",
    "            if i != j:  # Ensure no self-loops\n",
    "                G.add_edge(i, j, weight=fc_matrix[i][j])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98cb87d0bb64414b1dd7f563b56dc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing .pconn.nii files:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'graph_statistics.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the pconn files\n",
    "directory = \"C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/BSNIP_neural/BSNIP/pconn\"\n",
    "pconn_files = [f for f in os.listdir(directory) if f.endswith('.pconn.nii')]\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "for file_name in tqdm(pconn_files, desc=\"Processing .pconn.nii files\"):\n",
    "    fc_file_path = os.path.join(directory, file_name)\n",
    "    fc_matrix = load_fc_matrix(fc_file_path)\n",
    "    graph = create_knn_graph(fc_matrix, k=5)\n",
    "\n",
    "    degrees = [deg for _, deg in graph.degree()]\n",
    "    n = graph.number_of_nodes()\n",
    "    if n > 1:  # To avoid division by zero in calculations\n",
    "        average_degree = sum(degrees) / n\n",
    "        theoretical_avg_c = average_degree / (n - 1)\n",
    "        theoretical_avg_d = math.log(n) / math.log(average_degree) if average_degree > 1 else 0\n",
    "\n",
    "        # Calculate clustering and path length on the largest connected component\n",
    "        largest_cc = max(nx.connected_components(graph), key=len)\n",
    "        subgraph = graph.subgraph(largest_cc)\n",
    "        size_of_largest_cc = len(largest_cc)\n",
    "        avg_clustering = nx.average_clustering(graph)\n",
    "        avg_path_length = nx.average_shortest_path_length(subgraph) if len(largest_cc) > 1 else 0\n",
    "\n",
    "        row = [\n",
    "            file_name, n, average_degree, theoretical_avg_c, avg_clustering,\n",
    "            theoretical_avg_d, avg_path_length, math.log(n), math.log(math.log(n)),\n",
    "            size_of_largest_cc\n",
    "        ]\n",
    "    else:\n",
    "        row = [file_name, n, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    results.append(row)\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    'File Name', 'Number of Nodes', 'Average Degree', 'Theoretical Avg Clustering',\n",
    "    'Average Clustering', 'Theoretical Avg Path Length', 'Average Path Length',\n",
    "    'Log of Nodes', 'Log Log of Nodes', 'Size of Largest CC'\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('graph_statistics.csv', index=False)\n",
    "print(\"Data saved to 'graph_statistics.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def orca(G, exe_folder=\".\", output_folder=\".\"):\n",
    "    if \"orca.exe\" not in os.listdir(exe_folder):\n",
    "        raise Exception(exe_folder + \" doesn't contain orca.exe\")\n",
    "\n",
    "    input_filename = os.path.join(exe_folder, G.name + \".in\")\n",
    "    output_filename = os.path.join(output_folder, G.name + \".orca\")\n",
    "\n",
    "    # Write the input file\n",
    "    with open(input_filename, 'w') as file:\n",
    "        file.write(str(G.number_of_nodes()) + \" \" + str(G.number_of_edges()) + \"\\n\")\n",
    "        for i, j in G.edges():\n",
    "            file.write(f\"{i} {j}\\n\")\n",
    "\n",
    "    # Construct the command\n",
    "    command = [os.path.join(exe_folder, 'orca.exe'), \"node\", \"4\", input_filename, output_filename]\n",
    "    print(\"Running command:\", \" \".join(command))  # Print the command for debugging\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"STDOUT:\", result.stdout)\n",
    "        print(\"STDERR:\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"ERROR:\", e.stderr)\n",
    "        print(\"STDOUT:\", e.stdout)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Failed to execute command:\", e)\n",
    "        return None\n",
    "\n",
    "    # Check if the output file was created and read it\n",
    "    if not os.path.exists(output_filename) or os.stat(output_filename).st_size == 0:\n",
    "        print(\"Output file not created or is empty.\")\n",
    "        return None\n",
    "\n",
    "    # Read the results\n",
    "    orbits = []\n",
    "    with open(output_filename, 'r') as file:\n",
    "        for line in file:\n",
    "            orbits.append([int(k) for k in line.split()])\n",
    "\n",
    "    # Clean up files\n",
    "    os.remove(input_filename)\n",
    "    # Optionally remove the output file after processing, if desired\n",
    "    # os.remove(output_filename)\n",
    "\n",
    "    return orbits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/classifying_psychiatric_disorders/src/orca\\orca.exe node 4 C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/classifying_psychiatric_disorders/src/orca\\ExampleGraph.in C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/classifying_psychiatric_disorders/src/results_orca\\ExampleGraph.orca\n",
      "ERROR: \n",
      "STDOUT: \n"
     ]
    }
   ],
   "source": [
    "# Example usage of the modified function\n",
    "orca_folder = 'C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/classifying_psychiatric_disorders/src/orca'\n",
    "output_folder = 'C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/classifying_psychiatric_disorders/src/results_orca'\n",
    "directory = \"C:/Users/manfr/OneDrive/Escritorio/Manfred/EMAI/SecondSemester_Slovenia/Project/BSNIP_neural/BSNIP/pconn\"\n",
    "pconn_files = [f for f in os.listdir(directory) if f.endswith('.pconn.nii')]\n",
    "\n",
    "fc_file_path = os.path.join(directory, pconn_files[0])\n",
    "fc_matrix = load_fc_matrix(fc_file_path)\n",
    "graph = create_knn_graph(fc_matrix, k=5)\n",
    "graph.name = \"ExampleGraph\"  # Ensure the graph has a name attribute\n",
    "orbits1 = orca(graph, exe_folder=orca_folder, output_folder=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(orbits1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
