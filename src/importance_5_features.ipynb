{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'infomap', 'wurlitzer', 'bayanpy'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from cdlib.algorithms import leiden\n",
    "import nibabel as nib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_behavior(path):\n",
    "    # Reading\n",
    "    behavior_path = path\n",
    "    \n",
    "    behavior_files = os.listdir(behavior_path)\n",
    "    \n",
    "    behavior_source = pd.read_csv(behavior_path+behavior_files[0], sep='\\t')\n",
    "    for behavior_file in behavior_files[1:]:\n",
    "        curr_behavior_source = pd.read_csv(behavior_path+behavior_file, sep='\\t')\n",
    "        behavior_source = pd.concat([behavior_source, curr_behavior_source], axis=0)\n",
    "\n",
    "    return behavior_source\n",
    "\n",
    "def build_network(data, df, th_std, visualize = True):\n",
    "    # Create a graph from the data\n",
    "    # This example assumes 'data' is a square matrix where data[i][j] represents the connection\n",
    "    # strength between region i and region j. Your data's structure may vary.\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes with the brain region names or indices if you don't have names\n",
    "    num_regions = data.shape[0]\n",
    "    G.add_nodes_from(range(num_regions))\n",
    "    \n",
    "    # Add edges based on connectivity data\n",
    "    # Here we're simply adding an edge for every non-zero connection\n",
    "    for i in range(num_regions):\n",
    "        # Calculate the standard deviation of the specified row\n",
    "        std_dev = df.iloc[i].std()\n",
    "        threshold = th_std * std_dev\n",
    "        for j in range(i+1, num_regions):  # Ensure i < j to avoid duplicating edges\n",
    "            if abs(data[i, j]) > threshold:  # Assuming 0 means no connection\n",
    "                G.add_edge(i, j, weight=data[i, j])\n",
    "    \n",
    "    if visualize:\n",
    "        # You can also visualize the graph using matplotlib or similar libraries\n",
    "        # This step requires matplotlib to be installed (`pip install matplotlib`)\n",
    "        nx.draw(G, with_labels=True)\n",
    "        plt.show()\n",
    "        \n",
    "    return G\n",
    "\n",
    "def read_pconn(path):\n",
    "    \n",
    "    # Load the .pconn.nii file\n",
    "    img = nib.load(path)\n",
    "    \n",
    "    # Extract the data array from the image\n",
    "    # The data might need to be processed or reshaped depending on its structure\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/ahmet/Desktop/Study/second_semester/ds_project/BSNIP/pconn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pconn_paths = os.listdir('/Users/ahmet/Desktop/Study/second_semester/ds_project/BSNIP/pconn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_ids = [path.split('.')[0] for path in pconn_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_path = '/Users/ahmet/Desktop/Study/second_semester/ds_project/behavior/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_df = read_behavior(behavior_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important features found by feature selection process are ['X534', 'X484', 'X426', 'X284', 'X684']. These features corresponds to nodes 533, 483, 425, 283 and 683 because of 0 indexing. I will check if there is explanation to this nodes in the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_by_selection = [533, 483, 425, 283, 683]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hubs(G, group, std, session_id):\n",
    "    \n",
    "    degree_dict = dict(G.degree)\n",
    "    average_degree = (2 * G.number_of_edges()) / G.number_of_nodes()\n",
    "    imp_degree_dict = {key: degree_dict[key] for key in important_by_selection}\n",
    "    \n",
    "    hub = []\n",
    "    for k, v in imp_degree_dict.items():\n",
    "        if v > average_degree:\n",
    "            hub.append({'session_id' : session_id, 'group' : group, 'std': std, 'avg_degree': average_degree, 'feature' : k, 'hub_flag': True})\n",
    "        else:\n",
    "            hub.append({'session_id' : session_id , 'group' : group, 'std': std, 'avg_degree': average_degree, 'feature' : k, 'hub_flag': False})\n",
    "            \n",
    "    return hub\n",
    "\n",
    "def check_betweenness(G, group, std, th, session_id):\n",
    "    \n",
    "    bc_scores =  nx.betweenness_centrality(G)\n",
    "    top = sorted(bc_scores, key=bc_scores.get, reverse=True)[:th]\n",
    "    \n",
    "    bet = []\n",
    "    for feat in important_by_selection:\n",
    "        if feat in top:\n",
    "            bet.append({'session_id': session_id, 'group' : group, 'std': std, 'top' : th, 'feature' : feat, 'betweenness_flag': True})\n",
    "        else:\n",
    "            bet.append({'session_id': session_id, 'group': group, 'std': std,  'top' : th, 'feature' : feat, 'betweenness_flag': False})\n",
    "            \n",
    "    return bet\n",
    "\n",
    "def check_communities(session_id, group, G, th):\n",
    "    \n",
    "    mapping = leiden(G).to_node_community_map()\n",
    "    num_communities = len(leiden(G).communities)\n",
    "    \n",
    "    com = []\n",
    "    for feat in important_by_selection:\n",
    "        com.append({'session_id' : session_id, 'group' : group, 'std': th, 'feature' : feat, 'community': mapping[feat][0], 'num_communities': num_communities})\n",
    "    \n",
    "    return com\n",
    "\n",
    "def check_own_community(df):\n",
    "    \n",
    "    ''''This function checks if features are in the same or different communities\n",
    "    and assigns a flag feature.\n",
    "    '''\n",
    "    \n",
    "    result = []\n",
    "    for session_id, group in df.groupby('session_id'):\n",
    "        for community, community_group in group.groupby('community'):\n",
    "            if len(community_group) == 1:\n",
    "                row = community_group.iloc[0]\n",
    "                result.append((row['session_id'], row['group'], row['feature'], row['community'], True))\n",
    "            else:\n",
    "                for _, row in community_group.iterrows():\n",
    "                    result.append((row['session_id'], row['group'], row['feature'], row['community'], False))\n",
    "                    \n",
    "    res_df = pd.DataFrame(result, columns=['session_id', 'group', 'feature', 'community', 'forms_own_community'])\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = []\n",
    "hubs = []\n",
    "betweenness = []\n",
    "stds = [2, 3, 4.5]\n",
    "\n",
    "count = 0\n",
    "for std in stds:\n",
    "    for session_id, pconn_path in zip(session_ids, pconn_paths):\n",
    "        print(f'{count + 1}th Graph:')\n",
    "        group = behavior_df[behavior_df['session_id'] == session_id]['Group'].values[0]\n",
    "        path = os.path.join(base_path, pconn_path)\n",
    "        data, df = read_pconn(path)\n",
    "        G = build_network(data, df, std, visualize = False)\n",
    "        try:\n",
    "            hub = check_hubs(G, group, std, session_id)\n",
    "            hubs.append(hub)\n",
    "        except:\n",
    "            print('Exception occured for hubs')\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            bet = check_betweenness(G, group, std, 10, session_id)\n",
    "            betweenness.append(bet)\n",
    "        except:\n",
    "            print('Exception occured for betweenness')\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            com = check_communities(session_id, group, G, std)\n",
    "            community.append(com)\n",
    "        except:\n",
    "            print('Exception occured for communities')\n",
    "            pass\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df = pd.DataFrame([i for com in community for i in com])\n",
    "hub_df = pd.DataFrame([i for hub in hubs for i in hub])\n",
    "bet_df = pd.DataFrame([i for bet in betweenness for i in bet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_2 = com_df[com_df['std'] == 2]\n",
    "com_3 = com_df[com_df['std'] == 3]\n",
    "com_4_5 = com_df[com_df['std'] == 4.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUB RESULTS:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "std  feature\n",
       "2.0  283        0.141066\n",
       "     425        0.536050\n",
       "     483        0.253918\n",
       "     533        0.170846\n",
       "     683        0.260188\n",
       "3.0  283        0.117555\n",
       "     425        0.399687\n",
       "     483        0.197492\n",
       "     533        0.172414\n",
       "     683        0.133229\n",
       "4.5  283        0.003135\n",
       "     425        0.000000\n",
       "     483        0.007837\n",
       "     533        0.028213\n",
       "     683        0.001567\n",
       "Name: hub_flag, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETWEENNESS RESULTS:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "std  feature\n",
       "2.0  283        0.003135\n",
       "     425        0.001567\n",
       "     483        0.003135\n",
       "     533        0.000000\n",
       "     683        0.021944\n",
       "3.0  283        0.007837\n",
       "     425        0.015674\n",
       "     483        0.007837\n",
       "     533        0.003135\n",
       "     683        0.000000\n",
       "4.5  283        0.000000\n",
       "     425        0.000000\n",
       "     483        0.000000\n",
       "     533        0.000000\n",
       "     683        0.000000\n",
       "Name: betweenness_flag, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('HUB RESULTS:')\n",
    "print('-'*30)\n",
    "display(hub_df.groupby(['std','feature']).sum('hub_flag')['hub_flag'] / 638)\n",
    "print('BETWEENNESS RESULTS:')\n",
    "print('-'*30)\n",
    "display(bet_df.groupby(['std','feature']).sum('betweenness_flag')['betweenness_flag'] / 638)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no clear indicator that these 5 features appears as hubs in the graphs for any STD we picked. The results are 0 for 4.5 because most of nodes are going to be isolated in this case we can see that results also in community analysis later on. This means these 5 features didn't have any links to any other node. The results we would expect to say these are the hubs would be if they appear 80% or more time in the hubs.\n",
    "- Also for betweenness, I've checked if these nodes are appears in the top 10 nodes according to their betweenness centrality scores and it's seen that their percentages are really low so this cannot be explained by betweenness centrality either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUB RESULTS:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "std  feature  group\n",
       "2.0  283      BPP      0.037618\n",
       "              CON      0.036050\n",
       "              SADP     0.020376\n",
       "              SCZP     0.047022\n",
       "     425      BPP      0.128527\n",
       "              CON      0.173981\n",
       "              SADP     0.092476\n",
       "              SCZP     0.141066\n",
       "     483      BPP      0.057994\n",
       "              CON      0.081505\n",
       "              SADP     0.039185\n",
       "              SCZP     0.075235\n",
       "     533      BPP      0.032915\n",
       "              CON      0.034483\n",
       "              SADP     0.039185\n",
       "              SCZP     0.064263\n",
       "     683      BPP      0.065831\n",
       "              CON      0.073668\n",
       "              SADP     0.050157\n",
       "              SCZP     0.070533\n",
       "3.0  283      BPP      0.026646\n",
       "              CON      0.040752\n",
       "              SADP     0.025078\n",
       "              SCZP     0.025078\n",
       "     425      BPP      0.089342\n",
       "              CON      0.141066\n",
       "              SADP     0.073668\n",
       "              SCZP     0.095611\n",
       "     483      BPP      0.040752\n",
       "              CON      0.070533\n",
       "              SADP     0.031348\n",
       "              SCZP     0.054859\n",
       "     533      BPP      0.039185\n",
       "              CON      0.053292\n",
       "              SADP     0.031348\n",
       "              SCZP     0.048589\n",
       "     683      BPP      0.042320\n",
       "              CON      0.042320\n",
       "              SADP     0.020376\n",
       "              SCZP     0.028213\n",
       "4.5  283      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.001567\n",
       "              SCZP     0.001567\n",
       "     425      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     483      BPP      0.001567\n",
       "              CON      0.001567\n",
       "              SADP     0.000000\n",
       "              SCZP     0.004702\n",
       "     533      BPP      0.004702\n",
       "              CON      0.014107\n",
       "              SADP     0.004702\n",
       "              SCZP     0.004702\n",
       "     683      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.001567\n",
       "              SCZP     0.000000\n",
       "Name: hub_flag, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETWEENNESS RESULTS:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "std  feature  group\n",
       "2.0  283      BPP      0.001567\n",
       "              CON      0.001567\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     425      BPP      0.000000\n",
       "              CON      0.001567\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     483      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.003135\n",
       "     533      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     683      BPP      0.001567\n",
       "              CON      0.009404\n",
       "              SADP     0.006270\n",
       "              SCZP     0.004702\n",
       "3.0  283      BPP      0.001567\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.006270\n",
       "     425      BPP      0.001567\n",
       "              CON      0.004702\n",
       "              SADP     0.004702\n",
       "              SCZP     0.004702\n",
       "     483      BPP      0.000000\n",
       "              CON      0.004702\n",
       "              SADP     0.000000\n",
       "              SCZP     0.003135\n",
       "     533      BPP      0.001567\n",
       "              CON      0.001567\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     683      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "4.5  283      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     425      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     483      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     533      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "     683      BPP      0.000000\n",
       "              CON      0.000000\n",
       "              SADP     0.000000\n",
       "              SCZP     0.000000\n",
       "Name: betweenness_flag, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('HUB RESULTS:')\n",
    "print('-'*30)\n",
    "display(hub_df.groupby(['std','feature', 'group']).sum('hub_flag')['hub_flag'] / 638)\n",
    "print('BETWEENNESS RESULTS:')\n",
    "print('-'*30)\n",
    "display(bet_df.groupby(['std','feature', 'group']).sum('betweenness_flag')['betweenness_flag'] / 638)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check contriubtions from each group to the percentages we looked before, there is also no explanability found here. The results seems like pretty much random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 STD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>forms_own_community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>0.326019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>0.575235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533</td>\n",
       "      <td>0.297806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>0.299373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  forms_own_community\n",
       "0      283             0.326019\n",
       "1      425             0.575235\n",
       "2      483             0.363636\n",
       "3      533             0.297806\n",
       "4      683             0.299373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 STD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>forms_own_community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>0.885580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>0.937304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>0.873041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533</td>\n",
       "      <td>0.874608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>0.907524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  forms_own_community\n",
       "0      283             0.885580\n",
       "1      425             0.937304\n",
       "2      483             0.873041\n",
       "3      533             0.874608\n",
       "4      683             0.907524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 STD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>forms_own_community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>0.04232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>0.04232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>0.04232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533</td>\n",
       "      <td>0.04232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>0.04232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  forms_own_community\n",
       "0      283              0.04232\n",
       "1      425              0.04232\n",
       "2      483              0.04232\n",
       "3      533              0.04232\n",
       "4      683              0.04232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('2 STD:')\n",
    "res_2 = check_own_community(com_2)\n",
    "res_2 = res_2.groupby(['feature']).sum('forms_own_community')['forms_own_community'].reset_index()\n",
    "res_2['forms_own_community'] = res_2['forms_own_community'] / 638\n",
    "display(res_2)\n",
    "\n",
    "print('3 STD:')\n",
    "res_3 = check_own_community(com_3)\n",
    "res_3 = res_3.groupby(['feature']).sum('forms_own_community')['forms_own_community'].reset_index()\n",
    "res_3['forms_own_community'] = res_3['forms_own_community'] / 638\n",
    "display(res_3)\n",
    "\n",
    "print('4.5 STD:')\n",
    "res_4_5 = check_own_community(com_4_5)\n",
    "res_4_5 = res_4_5.groupby(['feature']).sum('forms_own_community')['forms_own_community'].reset_index()\n",
    "res_4_5['forms_own_community'] = res_4_5['forms_own_community'] / 638\n",
    "display(res_4_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for community detection seen above. I basically checked if these features were in the same community or not. We would expect them to be in different communities if they provide different informations to the machine learning algorithms. These was the main motivation.\n",
    "\n",
    "It's seen that for 2 STD the percentages again not that high. 3 STD seems perfect and what we would expect to see based on our assumptions but if we check the statistics for number of communities below, even with 3 STD most of the nodes are being isolated and forming its own community. That means because of high number of communities in average, these 5 features are in the different communities but it doesn't indicate that they form meaningful communities.\n",
    "The percentages are so low and same for all feature in STD 4.5 because community detection algorithm throws an error almost everytime since most of the nodes are isolated (That means it would be TRUE for all features and it would make percentages to get closer to the 1). We normalized values by 638 that's why percentages are so small. Actually, they are pretty much close 1 but I didn't bother to fix it since it's not informative because of high number of communities.\n",
    "\n",
    "In conclusion, if there was a result like 3 STD in 2 STD, we would conclude that these features forms its own communities. Unfortunately, any of these 3 statistics (hubs, betweenness centrality, community detection) didn't give explanation to the these 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 STD:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3190.000000\n",
       "mean       34.974922\n",
       "std       120.974158\n",
       "min         2.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         6.000000\n",
       "max       698.000000\n",
       "Name: num_communities, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 STD:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3180.000000\n",
       "mean      333.020440\n",
       "std       179.551163\n",
       "min        12.000000\n",
       "25%       191.000000\n",
       "50%       337.500000\n",
       "75%       469.000000\n",
       "max       707.000000\n",
       "Name: num_communities, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 STD:\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    135.000000\n",
       "mean     707.407407\n",
       "std        7.984403\n",
       "min      680.000000\n",
       "25%      706.000000\n",
       "50%      710.000000\n",
       "75%      713.000000\n",
       "max      716.000000\n",
       "Name: num_communities, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('2 STD:')\n",
    "print('-'*30)\n",
    "display(com_2.num_communities.describe())\n",
    "print('3 STD:')\n",
    "print('-'*30)\n",
    "display(com_3.num_communities.describe())\n",
    "print('4.5 STD:')\n",
    "print('-'*30)\n",
    "display(com_4_5.num_communities.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
